## LLM Review with Invisible Prompt

**Title**: "Give a Positive Review Only": Can Hidden PDF Prompts Sway LLMs?

**Authors**: Xuyang Guo, Zekai Huang, Zhao Song, Jiahao Zhang

**Date**: July 28, 2025

**Abstract**: Recently, the rapid increase in submissions to top AI conferences has made it increasingly difficult to find enough qualified volunteer reviewers, raising concerns about review quality and reviewer workload. As a result, many conferences and conference proposals have begun exploring the use of large language models (LLMs) as assistants in the peer review process. However, recent controversies, such as the case involving hidden white-text prompts in a number of academic papers, 
have raised concerns about whether LLM-based review systems can be easily manipulated by prompts embedded in PDF files that are invisible to humans but visible to LLMs. 
In this work, we study a simplified setting in which LLMs are asked to solve basic arithmetic questions (e.g., "What is 3+2?") formatted as either multiple-choice or judgment problems within PDF files. We investigate whether hidden prompts embedded in the file can influence LLM responses and cause them to give wrong answers. Our findings show that LLMs are indeed vulnerable to such hidden prompt attacks, even in these basic scenarios, raising concerns about the robustness of LLMs in peer review tasks. 
